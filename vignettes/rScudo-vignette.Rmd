---
title: "An introduction to rScudo"
date: "`r Sys.Date()`"
author:
-   name: Matteo Ciciani
    affiliation: &aff CIBIO, Univ. of Trento, Trento, Italy
    email: matteo.ciciani@gmail.com
-   name: Thomas Cantore
    affiliation: *aff
output:
    BiocStyle::pdf_document:
        #toc_float: true
vignette: >
    %\VignetteIndexEntry{Signature-based Clustering for Diagnostic Purposes}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>"
)
```

# Introduction

This package implements in R the SCUDO pipeline proposed in Lauria (2013) and
Lauria, Moyseos, Priami (2015).

SCUDO (Signature-based Clustering for Diagnostic Purposes) is a method for the
analysis of gene expression profiles for diagnostic and classification purposes.
The method is based on the idea of sample-specific gene signatures. The expected
result is the emergence of a partitioning of the set of samples in separate
clusters (propely, communities) on the basis of signature similarity.

# Method in brief

Starting from gene expression data, the functions `scudoTrain` and
`scudoNetwork` perform the basic SCUDO pipeline, which can be summarized in 4
steps:

1. First, fold-changes are computed for each gene. Then, a feature selection
step is performed. The user can specify whether to use a parametric or a non
parametric test. The test used also depends on the number of groups present in
the dataset. This step can be optionally skipped.

2. The subsequent operations include single sample gene ranking and the
extraction of signatures formed by up-regulated and down-regulated genes. The
length of the signatures are customizable. Consensus signtures are then
computed, both for up- and down-regulated genes and for each group. The
computation of consensus signatures is performed aggregating the ranks of the
genes in each sample and ranking again the genes.

3. An all-to-all distance matrix is then computed using a distance similar to
the Gene Set Enrichment Analysis (GSEA): the distance between two samples is
computed as the mean of the enrichment scores (ES) of the signature of each
sample in the expression profile of the other sample. The distance function used
is customizable.

4. Finally, a user-defined threshold N is used to generate a network of samples.
The distance matrix is treated as an adjacency matrix, but only the distances
that fall below the N^th^ quantile of distances are used to draw edges in the
network. This is performed by the function `scudoNetwork`.The network can then
be displayed in R or using Cytoscape.

The function `scudoTrain` returns an object of class `scudoResults`, which
contains sample specific gene signatures and consensus gene signatures for each
group specified and the sample distance matrix.

After the identification of a list of genes that can be used to partition the
samples in separated communities, the same procedure can be applied to a testig
dataset. The function `scudoTest` performs steps 2 and 3 on a testing dataset,
taking into account only the genes selected in the training phase.

Alteranatively, the function `scudoClassify` can be used to perform supervised
classification. This function takes as input a training set, containing samples
with known classification, and a testing set of samples with unknown
classification. For each sample in the testing set, the function computes a
network formed by all the samples in the training set and a single sample from
the training set. Then, classification scores are computed for each sample in
the testing set looking at the neighbors of that sample in the network. See the
documentation of the function for a detailed description of the computation of
the classification scores.

# Example workflow of rScudo

## Data preparation

In this example we will use the `r Biocpkg("ALL")` dataset, containing gene
expression data from T- and B-cells acute lymphoblastic leukemia patients. In
this first part, we are interested in distinguishing B-cells and T-cells
samples, based on gene expression profiles. We begin by loading relevant
libraries and subsetting the dataset, dividing it in a training and a testing
set, using the function `createDataPartition` from the package `r
CRANpkg("caret")`.

```{r, message=FALSE}
library(rScudo)
library(ALL)
data(ALL)

bt <- as.factor(stringr::str_extract(pData(ALL)$BT, "^."))

set.seed(1111)
inTrain <- caret::createDataPartition(bt, list = FALSE)
trainData <- ALL[, inTrain]
testData <- ALL[, -inTrain]
```

## Analysis of the training set

We start by analyzing the training set. We first run `scudoTrain`, which returns
an object of class `ScudoResults`.

```{r}
trainRes <- scudoTrain(trainData, groups = bt[inTrain], nTop = 100,
    nBottom = 100, alpha = 0.1)
trainRes
```

From this object we can extract the signatures for each sample and the consensus
signatures for each group.

```{r}
upSignatures(trainRes)[1:5,1:5]
consensusUpSignatures(trainRes)[1:5, ]
```

The function `ScudoNetwork` can be used to generate a network of samples from
the object `trainRes` . This function returns an `r CRANpkg("igraph")` object.
The parameter `N` controls the percentage of edges to keep in the network. We
can plot this network using the function `scudoPlot`.

```{r}
trainNet <- scudoNetwork(trainRes, N = 0.2)
scudoPlot(trainNet, vertex.label = NA)
```

You can also render the network in Cytoscape, using the function
`ScudoCytoscape`. Note that Cytoscape has to be open when running the function.

```{r, eval=FALSE}
scudoCytoscape(trainNet)
```

Since we obtained a very good separation of the two groups, we proceed to
analyze the testing set.

## Analysis of the testing set

We can use a `ScudoResults` object and the function `scudoTest` to analyze the
testing set. The feature selection is not performed in the testing set. Instead,
only the features selected in the training are used in the analysis of the
testing set.

```{r}
testRes <- scudoTest(trainRes, testData, bt[-inTrain], nTop = 100,
    nBottom = 100)
testRes
```

We can generate a network of samples and plot it.

```{r}
testNet <- scudoNetwork(testRes, N = 0.2)
scudoPlot(testNet, vertex.label = NA)
```

We can use a community clustering algorithm to identify clusters of samples. In
the following example we use the function `cluster_spinglass` from the package
`r CRANpkg("igraph")` to perform clustering of our network. In Cytoscape we can
perform a similar analysis using clustering functions from the clusterMaker app.

```{r}
testClust <- igraph::cluster_spinglass(testNet, spins = 2)
plot(testClust, testNet, vertex.label = NA)
```

### Supervised classification

`scudoClassify` performs supervised classification of sample in a testing set
using a model built from samples in a training set. It uses a method based on
neighbors in the graph to assign a class label to each sample in the testing
set. We suggest to use the same `N`, `nTop`, `nBottom` and `alpha` that were
used in the training step.

```{r}
classRes <- scudoClassify(trainData, testData, N = 0.2, nTop = 100,
    nBottom = 100, trainGroups = bt[inTrain], alpha = 0.1)
```

Classification performances can be explored using the `confusionMatrix` function
from `r CRANpkg("caret")`.

```{r}
caret::confusionMatrix(classRes$predicted, bt[-inTrain])
```

## Example of multigroup analysis

The analysis can also be performed on more than two groups. In this section, we
try to predict the stage of B-cells ALL using gene expression data. We focus
only on stages B1, B2 and B3, since they have an adequate numerosity.

```{r}
BCells <- which(as.character(ALL$BT) %in% c("B1", "B2", "B3"))
ALLB <- ALL[, BCells]
stage <- ALLB$BT[, drop = TRUE]
table(stage)
```

We divide the dataset in a training and a testing set and we apply `scudoTrain`,
identifying suitable parameter values. Then, we perform supervised
classification of the samples in the testing set using the function
`scudoClassify`.

```{r}
inTrain <- as.vector(caret::createDataPartition(stage, p = 0.6, list = FALSE))

stageRes <- scudoTrain(ALLB[, inTrain], stage[inTrain], 100, 100, 0.01)
stageNet <- scudoNetwork(stageRes, 0.2)
scudoPlot(stageNet, vertex.label = NA)

classStage <- scudoClassify(ALLB[, inTrain], ALLB[, -inTrain], 0.25, 100, 100,
    stage[inTrain], alpha = 0.01)
caret::confusionMatrix(classStage$predicted, stage[-inTrain])
```

## Increasing performance through parameters tuning 

Parameters such as `nTop` and `nBottom` can be optimally tuned through many 
techniques such as cross validation.
The `r CRANpkg("caret")` offers an efficient way to compute grid search for 
optimal parameters tuning through cross validation. The package gives the opportunity to 
[use your own model in `train` function](http://topepo.github.io/caret/using-your-own-model-in-train.html).\
Here we report an example of script that could be used for such purpose, 
in the multigroup analysis previously performed.
Since feature selection represents a bottleneck in rScudo performance, 
we compute it, together with foldChange before the cross-validation. 


```{r, eval=FALSE}
# fold change and feature selection --------------------------------------------

trainDataNorm <- exprs(ALLB[, inTrain])
virtControl <- rowMeans(trainDataNorm)
trainDataNorm <- trainDataNorm / virtControl
pVals <- apply(trainDataNorm, 1, function(x) {
    stats::kruskal.test(x, stage[inTrain])$p.value})
trainDataNorm <- trainDataNorm[pVals <= 0.01, ]

# preparing model list ---------------------------------------------------------

rSC <- list(type = "Classification",
            library = "rScudo",
            parameters = data.frame(parameter = c("nTop", "nBottom"), 
                                    class = rep("numeric", 2),
                                    label = c("Number Top Signatures",
                                              "Number Bottom Signatures")),
            
            grid = function(x, y, len = NULL, search = "random") {
                rngSigUp <- round(runif(len, min = 1, max = 150))
                rngSigDown <- round(runif(len, min = 1, max = 150))
                out <- data.frame(nTop = rngSigUp, nBottom = rngSigDown)
                out                  
            },
            fit = function(x, y, wts, param, lev, last, 
                           weights, classProbs, ...) { 
                out <- rScudo::scudoTrain(expressionData = t(x), 
                                          groups = y, 
                                          nTop = param$nTop, 
                                          nBottom = param$nBottom,
                                          featureSel = F,
                                          foldChange = F,
                                          ...)
                out@params$trainData <- x
                out@params$trainGroups <- y
                out 
            },
            predict = function(modelFit, newdata, 
                               preProc = NULL, submodels = NULL){
                rScudo::scudoClassify(
                    trainExpData = t(modelFit@params$trainData),
                    testExpData = t(newdata), 
                    trainGroups = modelFit@params$trainGroups,
                    N = 0.25, 
                    nTop = modelFit@params$nTop, 
                    nBottom = modelFit@params$nBottom, 
                    featureSel = F,
                    foldChange = F)$predicted
            },
            prob = function(modelFit, newdata, 
                            preProc = NULL, submodels = NULL){
                rScudo::scudoClassify(
                    trainExpData = t(modelFit@params$trainData),
                    testExpData = t(newdata), 
                    trainGroups = modelFit@params$trainGroups,
                    N = 0.25, 
                    nTop = modelFit@params$nTop, 
                    nBottom = modelFit@params$nBottom, 
                    featureSel = F,
                    foldChange = F)$scores
            })

# Running parameter tuning ----------------------------------------------------- 

cl <- parallel::makePSOCKcluster(2)
doParallel::registerDoParallel(cl)
fitControl <- trainControl(method = "boot",
                           number = 5,
                           summaryFunction = multiClassSummary)
mod <- train(x = t(trainDataNorm), 
             y = stage[inTrain],
             method = rSC, 
             tuneLength = 50, 
             trControl = fitControl)

stopCluster(cl) # warnings 

```

In this case on 50 randomly chosen values in a range between 1 and 150, possibly
optimal values suggested for nTop and nBottom are respectively: 69 and 48\
Running scudoClassify on testData from the multigroup example 

```{r}
classStage <- scudoClassify(ALLB[, inTrain], ALLB[, -inTrain], 0.25, 39, 64,
    stage[inTrain], alpha = 0.01)
caret::confusionMatrix(classStage$predicted, stage[-inTrain])
```
 The overall performance increases as it is possible to see from the confusion 
 matrix. 
 
# Session info

```{r}
sessionInfo()
```

# References

Mario Lauria. Rank-based transcriptional signatures. Systems Biomedicine. 2013;
1(4):228-239.

Mario Lauria, Petros Moyseos and Corrado Priami. SCUDO: a tool for
signature-based clustering of expression profiles. Nucleic Acids Research. 2015;
43(W1):W188-92.
